{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.vocab import vocab\n",
    "from torch import nn\n",
    "import os \n",
    "import sys\n",
    "from box_embeddings.modules.volume.volume import Volume\n",
    "from box_embeddings.modules.intersection import Intersection\n",
    "from utils.model import BoxModel\n",
    "sys.path.append(\"../\")\n",
    "model = torch.load(\"/home/fmollica/Desktop/word2box_pytorch/weights/skipgram_WikiText2/epochs_2_min_count_50_batch_size_512_embed_dim_3_lr_0.001_window_10_neg_count_10/model_final.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoxModel(\n",
       "  (embeddings_word): BoxEmbedding(3520, 6)\n",
       "  (embeddings_context): BoxEmbedding(3520, 6)\n",
       "  (box_vol): Volume()\n",
       "  (box_int): Intersection()\n",
       "  (vocab): Vocab()\n",
       ")"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_2(word, N=None):\n",
    "\n",
    "        if N is None:\n",
    "            N = len(model.vocab)\n",
    "\n",
    "        embedding_all_target = model.embeddings_word.all_boxes\n",
    "\n",
    "        \n",
    "        index_word = (model.vocab[word])\n",
    "        print(index_word)\n",
    "        embedding_word = embedding_all_target[index_word]\n",
    "                \n",
    "        # sim3 = torch.exp(self.box_vol(self.box_int(embedding_all_target, embedding_word))-torch.minimum(self.box_vol(embedding_all_target), self.box_vol(embedding_word)))\n",
    "            \n",
    "        # idx = (-sim3).argsort()\n",
    "        \n",
    "\n",
    "        sim3 = torch.exp(model.box_vol(model.box_int(embedding_all_target, embedding_word))- torch.maximum(model.box_vol(embedding_word),model.box_vol(embedding_all_target)))\n",
    "\n",
    "        idx = (-sim3).argsort()\n",
    "\n",
    "        print(idx[0:50])\n",
    "\n",
    "        for i, index in enumerate(idx[0:50]):\n",
    "            print(\"Similar to : \", str(index.item()),   model.vocab.lookup_token(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007327903877012432\n",
      "Uno  0.0007327903877012432  Due  0.0007327903877012432\n",
      "1.0\n",
      "0.0006932641845196486\n",
      "Uno  tensor(0.0007, device='cuda:0', grad_fn=<ExpBackward0>)  Due  tensor(0.0078, device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "0.08904954791069031\n"
     ]
    }
   ],
   "source": [
    "uno = model.embeddings_word.all_boxes[143]\n",
    "due = model.embeddings_word.all_boxes[143]\n",
    "vol = Volume(volume_temperature=0.1, intersection_temperature=0.0001)\n",
    "inte = Intersection(intersection_temperature=0)\n",
    "\n",
    "print(torch.exp(vol(inte(uno, due))).item())\n",
    "print(\"Uno \" , torch.exp(vol(uno)).item(), \" Due \" , torch.exp(vol(due)).item())\n",
    "\n",
    "print(torch.exp(vol(inte(uno, due)) -  torch.maximum(vol(uno), vol(due))).item())\n",
    "\n",
    "uno = model.embeddings_word.all_boxes[143]\n",
    "due = model.embeddings_word.all_boxes[126]\n",
    "print(torch.exp(vol(inte(uno, due))).item())\n",
    "print(\"Uno \" , torch.exp(vol(uno)), \" Due \" , torch.exp(vol(due)))\n",
    "print(torch.exp(vol(inte(uno, due)) -  torch.maximum(vol(uno), vol(due))).item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "tensor([  32, 2139, 1316,  928, 1637,  387, 1001, 2959,  353,   97, 1421,  852,\n",
      "         475, 1549, 1081, 3010,  529, 2386,  311,  252, 1289,  447, 1260,  669,\n",
      "         418,  245, 2290, 3469,  191, 1628,  996,  456,  596,  312, 3272, 2825,\n",
      "         831,   67, 1879,  775,  249,  439,  496, 1539, 3192,  863,  877,  433,\n",
      "         329, 2442], device='cuda:0')\n",
      "Similar to :  32 war\n",
      "Similar to :  2139 example\n",
      "Similar to :  1316 prominent\n",
      "Similar to :  928 including\n",
      "Similar to :  1637 album\n",
      "Similar to :  387 could\n",
      "Similar to :  1001 market\n",
      "Similar to :  2959 slam\n",
      "Similar to :  353 stated\n",
      "Similar to :  97 part\n",
      "Similar to :  1421 minute\n",
      "Similar to :  852 paper\n",
      "Similar to :  475 sold\n",
      "Similar to :  1549 ninth\n",
      "Similar to :  1081 described\n",
      "Similar to :  3010 soviet\n",
      "Similar to :  529 include\n",
      "Similar to :  2386 isle\n",
      "Similar to :  311 however\n",
      "Similar to :  252 woman\n",
      "Similar to :  1289 male\n",
      "Similar to :  447 duty\n",
      "Similar to :  1260 dark\n",
      "Similar to :  669 artillery\n",
      "Similar to :  418 seven\n",
      "Similar to :  245 wish\n",
      "Similar to :  2290 meanwhile\n",
      "Similar to :  3469 xenon\n",
      "Similar to :  191 used\n",
      "Similar to :  1628 strength\n",
      "Similar to :  996 finally\n",
      "Similar to :  456 appearance\n",
      "Similar to :  596 tower\n",
      "Similar to :  312 following\n",
      "Similar to :  3272 sweet\n",
      "Similar to :  2825 settlement\n",
      "Similar to :  831 near\n",
      "Similar to :  67 may\n",
      "Similar to :  1879 musician\n",
      "Similar to :  775 well\n",
      "Similar to :  249 destroyed\n",
      "Similar to :  439 later\n",
      "Similar to :  496 coming\n",
      "Similar to :  1539 g\n",
      "Similar to :  3192 biological\n",
      "Similar to :  863 change\n",
      "Similar to :  877 month\n",
      "Similar to :  433 constructed\n",
      "Similar to :  329 killed\n",
      "Similar to :  2442 growing\n"
     ]
    }
   ],
   "source": [
    "most_similar_2(\"war\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
