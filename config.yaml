model_name: skipgram
model_dir: weights/skipgram_WikiText103
dataset: WikiText103
data_dir: data/
optimizer: Adam
train_batch_size: 
learning_rate: 
epochs: 10
skipgram_n_words: 
min_word_frequency:
neg_count: 
embed_dimension: 2
n_print: 50
max_sequence_length: 256
